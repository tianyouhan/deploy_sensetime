import tensorrt as trt
import numpy as np
import os
import json
import io
import base64
import pycuda.driver as cuda
import pycuda.autoinit
import argparse

# -----------------------------
# å‘½ä»¤è¡Œå‚æ•° / é…ç½®å¼€å…³
# -----------------------------
parser = argparse.ArgumentParser()
parser.add_argument("--markAllOutputs", action="store_true", help="æ ‡è®°æ‰€æœ‰ä¸­é—´å±‚è¾“å‡º")
args = parser.parse_args()

MARK_ALL_OUTPUTS = args.markAllOutputs

# -----------------------------
# é…ç½® - åŠ¨æ€shapeè®¾ç½®
# -----------------------------
onnx_path = "/mnt/data/hantianyou/fsdv2/pts_backbone/spetr.onnx"   # ONNX æ¨¡å‹è·¯å¾„
engine_path = "/mnt/data/hantianyou/road_compare_tool/layer_check/save_trt/pts_fp32_all_layers.trt"                                # ä¿å­˜çš„ TensorRT engine è·¯å¾„
output_json_path = "/mnt/data/hantianyou/road_compare_tool/layer_check/save_outputs/pts_outputs_fp16_select.json"                         # è¾“å‡º JSON è·¯å¾„
input_dir = "/mnt/data/hantianyou/2025_10_14_test/save_tensors/pts_backbone_align_npy"  # è¾“å…¥æ•°æ®æ–‡ä»¶å¤¹ï¼ˆ.npyï¼‰

# åŠ¨æ€shapeé…ç½®
DYNAMIC_SHAPES = {
    'voxel_coords': {
        'min': [1, 2],
        'opt': [20000, 2], 
        'max': [20000, 2]
    },
    'vfe_input': {
        'min': [1, 9, 32, 1],
        'opt': [20000, 9, 32, 1],
        'max': [20000, 9, 32, 1]
    }
}

fp32_layers_set = [
    "/model/Mul",
    "/model/Concat",
    "/model/Unsqueeze_1",
    "/model/Expand_1",
    "/model/Cast",
    "/model/Add",
    "/model/Add_1",
    "/model/ScatterND",
]

# -----------------------------
# åˆå§‹åŒ– TRT
# -----------------------------
TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE)  # æ”¹ä¸ºVERBOSEä»¥ä¾¿æŸ¥çœ‹æ›´å¤šä¿¡æ¯
trt.init_libnvinfer_plugins(TRT_LOGGER, "")

builder = trt.Builder(TRT_LOGGER)
network_flags = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)
network = builder.create_network(network_flags)

parser = trt.OnnxParser(network, TRT_LOGGER)
with open(onnx_path, "rb") as f:
    if not parser.parse(f.read()):
        for i in range(parser.num_errors):
            print(parser.get_error(i))
        raise RuntimeError("ONNX parse failed")

print(f"âœ… ONNXè§£ææˆåŠŸï¼Œç½‘ç»œæœ‰ {network.num_inputs} ä¸ªè¾“å…¥ï¼Œ{network.num_outputs} ä¸ªè¾“å‡º")

# æ‰“å°è¾“å…¥ä¿¡æ¯
for i in range(network.num_inputs):
    input_tensor = network.get_input(i)
    print(f"è¾“å…¥ {i}: {input_tensor.name}, shape: {input_tensor.shape}")

# -----------------------------
# æ ¹æ®å¼€å…³å†³å®šæ˜¯å¦å¯¼å‡ºä¸­é—´å±‚
# -----------------------------
if MARK_ALL_OUTPUTS:
    print("ğŸ”¹ æ ‡è®°æ‰€æœ‰ä¸­é—´å±‚è¾“å‡ºä¸º network output ...")
    for i in range(network.num_layers):
        layer = network.get_layer(i)
        for j in range(layer.num_outputs):
            tensor = layer.get_output(j)
            if tensor and not tensor.is_network_output:
                network.mark_output(tensor)
    print(f"âœ… å·²æ ‡è®° {network.num_outputs} ä¸ªè¾“å‡ºå¼ é‡")
else:
    print("âš™ï¸ ä»…ä¿ç•™æœ€ç»ˆè¾“å‡ºå±‚ï¼Œä¸å¯¼å‡ºä¸­é—´å±‚ã€‚")

# -----------------------------
# BuilderConfig - æ·»åŠ åŠ¨æ€shapeæ”¯æŒ
# -----------------------------
config = builder.create_builder_config()
config.set_flag(trt.BuilderFlag.FP16)
if hasattr(trt.BuilderFlag, "TF32"):
    config.clear_flag(trt.BuilderFlag.TF32)

# è®¾ç½®åŠ¨æ€shapeä¼˜åŒ–é…ç½®æ–‡ä»¶
print("=== è®¾ç½®åŠ¨æ€shapeä¼˜åŒ–é…ç½®æ–‡ä»¶ ===")
profile = builder.create_optimization_profile()

# ä¸ºæ¯ä¸ªè¾“å…¥è®¾ç½®åŠ¨æ€shapeèŒƒå›´
for i in range(network.num_inputs):
    input_tensor = network.get_input(i)
    input_name = input_tensor.name
    
    if input_name in DYNAMIC_SHAPES:
        shape_config = DYNAMIC_SHAPES[input_name]
        min_shape = shape_config['min']
        opt_shape = shape_config['opt'] 
        max_shape = shape_config['max']
        
        print(f"è®¾ç½®è¾“å…¥ '{input_name}' åŠ¨æ€shape:")
        print(f"  min: {min_shape}")
        print(f"  opt: {opt_shape}")
        print(f"  max: {max_shape}")
        
        profile.set_shape(input_name, min_shape, opt_shape, max_shape)
    else:
        # å¯¹äºéåŠ¨æ€è¾“å…¥ï¼Œä½¿ç”¨å›ºå®šshape
        shape = list(input_tensor.shape)
        print(f"è®¾ç½®è¾“å…¥ '{input_name}' å›ºå®šshape: {shape}")
        profile.set_shape(input_name, shape, shape, shape)

config.add_optimization_profile(profile)

# -----------------------------
# è®¾ç½®æ•æ„Ÿå±‚ FP32
# -----------------------------
for i in range(network.num_layers):
    layer = network.get_layer(i)
    set_fp32 = False

    # # è‡ªåŠ¨åŒ¹é… MatMul
    # if layer.type == trt.LayerType.MATRIX_MULTIPLY:
    #     set_fp32 = True

    # elif layer.type == trt.LayerType.ELEMENTWISE:
    #     # ç›´æ¥é€šè¿‡ getattr å®‰å…¨è®¿é—® operation å±æ€§
    #     op = getattr(layer, "operation", None)
    #     if op == trt.ElementWiseOperation.DIV:
    #         print(f"[DIV match] {i:4d} | {layer.name}")
    #         set_fp32 = True
            
    # if layer.type == trt.LayerType.SOFTMAX:
    #     set_fp32 = True

    # æ‰‹åŠ¨åˆ—è¡¨åŒ¹é…
    normalized_layer_name = layer.name.replace('/', '.').replace('_output_0', '').strip()
    for name in fp32_layers_set:
        normalized_name = name.replace('/', '.').replace('_output_0', '').strip()
        if normalized_name in normalized_layer_name:
            set_fp32 = True
            break

    # 3ï¸âƒ£ è®¾ç½® FP32ï¼Œä½†è·³è¿‡å¸¸é‡æƒé‡ç±»å‹ä¸å…è®¸çš„
    if set_fp32:
        for j in range(layer.num_outputs):
            out_tensor = layer.get_output(j)
            # ä»…å¯¹éæ•´æ•°å¸¸é‡è¾“å‡ºè®¾ç½® FP32
            if out_tensor.dtype != trt.DataType.INT32 and out_tensor.dtype != trt.DataType.INT64:
                try:
                    layer.precision = trt.DataType.FLOAT
                    layer.set_output_type(j, trt.DataType.FLOAT)
                    print(f"Found node {layer.name} ({layer.type}) to FP32")
                except Exception as e:
                    print(f"âš ï¸ Cannot set FP32 for layer {layer.name}: {e}")
            else:
                print(f"âš ï¸ Skip FP32 for {layer.name} output {j} because dtype={out_tensor.dtype}")
# import pdb;pdb.set_trace()
# -----------------------------
# æ„å»º engine
# -----------------------------
print("\n=== å¼€å§‹æ„å»º engine ===")
try:
    serialized_engine = builder.build_serialized_network(network, config)
    if serialized_engine is None:
        raise RuntimeError("Failed to build engine!")
    
    with open(engine_path, "wb") as f:
        f.write(serialized_engine)
    print(f"âœ… å·²ç”Ÿæˆæ··åˆç²¾åº¦ engine: {engine_path}")
    
except Exception as e:
    print(f"âŒ æ„å»ºå¤±è´¥: {e}")
    # å°è¯•ä¸ä½¿ç”¨FP16
    print("å°è¯•ä½¿ç”¨FP32æ„å»º...")
    config.clear_flag(trt.BuilderFlag.FP16)
    serialized_engine = builder.build_serialized_network(network, config)
    if serialized_engine:
        with open(engine_path, "wb") as f:
            f.write(serialized_engine)
        print(f"âœ… ä½¿ç”¨FP32ç”Ÿæˆ engine: {engine_path}")
    else:
        raise RuntimeError("FP32æ„å»ºä¹Ÿå¤±è´¥äº†!")

# -----------------------------
# åŠ è½½ engine å¹¶è¿›è¡Œæ¨ç†
# -----------------------------
runtime = trt.Runtime(TRT_LOGGER)
with open(engine_path, "rb") as f:
    engine = runtime.deserialize_cuda_engine(f.read())

context = engine.create_execution_context()

# -----------------------------
# åˆ†é… CUDA buffer - ç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…åŠ¨æ€shapeçš„å¤æ‚æ€§
# -----------------------------
print("=== å¼€å§‹åˆ†é… CUDA å†…å­˜ ===")

# é¦–å…ˆæ”¶é›†è¾“å…¥æ•°æ®
input_data = {}
input_shapes = {}
print("\n=== åŠ è½½è¾“å…¥æ•°æ®å¹¶ç¡®å®šshape ===")
for fname in os.listdir(input_dir):
    if fname.endswith(".npy"):
        key = fname.replace(".npy", "")
        arr = np.load(os.path.join(input_dir, fname)).astype(np.float32)
        input_data[key] = arr
        input_shapes[key] = arr.shape
        print(f"è¾“å…¥ {key}: shape={arr.shape}, min={arr.min():.6f}, max={arr.max():.6f}")

# åˆ†é…å†…å­˜ - ä½¿ç”¨æ–°API
bindings = []
cuda_buffers = {}

if hasattr(engine, 'num_io_tensors'):
    # TensorRT 8.5+ æ–° API
    num_io_tensors = engine.num_io_tensors
    tensor_names = [engine.get_tensor_name(i) for i in range(num_io_tensors)]
    
    print(f"\nä½¿ç”¨æ–°APIï¼Œå…±æœ‰ {num_io_tensors} ä¸ªIO tensors")
    
    for name in tensor_names:
        try:
            # å¯¹äºè¾“å…¥ï¼Œä½¿ç”¨å®é™…æ•°æ®çš„shape
            if engine.get_tensor_mode(name) == trt.TensorIOMode.INPUT:
                if name in input_shapes:
                    shape = input_shapes[name]
                    # è®¾ç½®è¾“å…¥shape
                    context.set_input_shape(name, shape)
                    print(f"è®¾ç½®è¾“å…¥shape: {name} -> {shape}")
                else:
                    print(f"âš ï¸ è­¦å‘Š: è¾“å…¥ {name} æ²¡æœ‰å¯¹åº”çš„æ•°æ®æ–‡ä»¶")
                    continue
            else:
                # å¯¹äºè¾“å‡ºï¼Œè·å–å½“å‰shape
                shape = context.get_tensor_shape(name)
            
            dtype = trt.nptype(engine.get_tensor_dtype(name))
            volume = trt.volume(shape)
            size = volume * np.dtype(dtype).itemsize
            
            print(f"åˆ†é…: {name}, shape: {shape}, dtype: {dtype}, size: {size} bytes")
            
            buffer = cuda.mem_alloc(size)
            cuda_buffers[name] = buffer
            bindings.append(int(buffer))
            
        except Exception as e:
            print(f"âŒ å¤„ç†tensor {name}æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

else:
    # æ—§ API
    print(f"ä½¿ç”¨æ—§APIï¼Œå…±æœ‰ {engine.num_bindings} ä¸ªbindings")
    
    for i in range(engine.num_bindings):
        try:
            name = engine.get_binding_name(i)
            dtype = trt.nptype(engine.get_binding_dtype(i))
            
            # å¯¹äºè¾“å…¥ï¼Œä½¿ç”¨å®é™…æ•°æ®çš„shape
            if engine.binding_is_input(i):
                if name in input_shapes:
                    shape = input_shapes[name]
                    # è®¾ç½®è¾“å…¥shape
                    context.set_binding_shape(i, shape)
                    print(f"è®¾ç½®è¾“å…¥shape: {name} -> {shape}")
                else:
                    print(f"âš ï¸ è­¦å‘Š: è¾“å…¥ {name} æ²¡æœ‰å¯¹åº”çš„æ•°æ®æ–‡ä»¶")
                    continue
            else:
                # å¯¹äºè¾“å‡ºï¼Œè·å–å½“å‰shape
                shape = context.get_binding_shape(i)
            
            volume = trt.volume(shape)
            size = volume * np.dtype(dtype).itemsize
            
            print(f"åˆ†é…: {name}, shape: {shape}, dtype: {dtype}, size: {size} bytes")
            
            buffer = cuda.mem_alloc(size)
            cuda_buffers[name] = buffer
            bindings.append(int(buffer))
            
        except Exception as e:
            print(f"âŒ å¤„ç†binding {i} ({name})æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

print(f"\n=== å†…å­˜åˆ†é…å®Œæˆ ===")
print(f"æˆåŠŸåˆ†é…äº† {len(cuda_buffers)} ä¸ª buffers")

# -----------------------------
# è½½å…¥è¾“å…¥æ•°æ®åˆ°GPU
# -----------------------------
print("\n=== æ‹·è´è¾“å…¥æ•°æ®åˆ°GPU ===")
for name, arr in input_data.items():
    if name in cuda_buffers:
        try:
            # ç¡®ä¿æ•°æ®æ˜¯è¿ç»­çš„å¹¶ä¸”ç±»å‹æ­£ç¡®
            arr_contiguous = np.ascontiguousarray(arr.astype(np.float32))
            cuda.memcpy_htod(cuda_buffers[name], arr_contiguous)
            print(f"âœ… å·²åŠ è½½è¾“å…¥: {name}, shape: {arr.shape}")
        except Exception as e:
            print(f"âŒ åŠ è½½è¾“å…¥ {name} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    else:
        print(f"âš ï¸ è¾“å…¥ {name} æ²¡æœ‰å¯¹åº”çš„CUDA buffer")

# -----------------------------
# æ‰§è¡Œæ¨ç†
# -----------------------------
print("\n=== å¼€å§‹æ¨ç† ===")
try:
    # æ£€æŸ¥æ‰€æœ‰ç»‘å®šå½¢çŠ¶æ˜¯å¦æœ‰æ•ˆ
    if hasattr(context, 'all_binding_shapes_specified'):
        if not context.all_binding_shapes_specified:
            print("âŒ é”™è¯¯: ä¸æ˜¯æ‰€æœ‰ç»‘å®šçš„å½¢çŠ¶éƒ½å·²æŒ‡å®š")
    
    if hasattr(context, 'all_shape_inputs_specified'):  
        if not context.all_shape_inputs_specified:
            print("âŒ é”™è¯¯: ä¸æ˜¯æ‰€æœ‰å½¢çŠ¶è¾“å…¥éƒ½å·²æŒ‡å®š")
    
    if hasattr(context, 'execute_v2'):
        success = context.execute_v2(bindings)
    else:
        success = context.execute_v1(bindings)
        
    if success:
        print("âœ… æ¨ç†å®Œæˆ")
    else:
        print("âŒ æ¨ç†æ‰§è¡Œè¿”å›å¤±è´¥")
        
except Exception as e:
    print(f"âŒ æ¨ç†å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# -----------------------------
# æ‹·è´è¾“å‡º
# -----------------------------
outputs = {}
print("\n=== å¼€å§‹æ‹·è´è¾“å‡º ===")

if hasattr(engine, 'num_io_tensors'):
    # æ–° API
    tensor_names = [engine.get_tensor_name(i) for i in range(engine.num_io_tensors)]
    for name in tensor_names:
        if engine.get_tensor_mode(name) == trt.TensorIOMode.OUTPUT:
            if name in cuda_buffers:
                try:
                    dtype = trt.nptype(engine.get_tensor_dtype(name))
                    shape = context.get_tensor_shape(name)
                    
                    print(f"æ‹·è´è¾“å‡º: {name}, shape: {shape}, dtype: {dtype}")
                    
                    host_arr = np.empty(shape, dtype=dtype)
                    cuda.memcpy_dtoh(host_arr, cuda_buffers[name])
                    outputs[name] = host_arr
                    
                    # ç«‹å³æ£€æŸ¥è¾“å‡ºæ˜¯å¦å…¨é›¶
                    if np.all(host_arr == 0):
                        print(f"âš ï¸ è­¦å‘Š: è¾“å‡º {name} å…¨éƒ¨ä¸º0!")
                    else:
                        print(f"âœ… æˆåŠŸæ‹·è´è¾“å‡º: {name}, éé›¶å€¼èŒƒå›´: [{host_arr.min():.6f}, {host_arr.max():.6f}]")
                        
                except Exception as e:
                    print(f"âŒ æ‹·è´è¾“å‡º {name} å¤±è´¥: {e}")
            else:
                print(f"âŒ è¾“å‡ºtensor '{name}' ä¸åœ¨cuda_buffersä¸­")
else:
    # æ—§ API
    for i in range(engine.num_bindings):
        name = engine.get_binding_name(i)
        if not engine.binding_is_input(i):
            if name in cuda_buffers:
                try:
                    dtype = trt.nptype(engine.get_binding_dtype(i))
                    shape = context.get_binding_shape(i)
                    
                    print(f"æ‹·è´è¾“å‡º: {name}, shape: {shape}, dtype: {dtype}")
                    
                    host_arr = np.empty(shape, dtype=dtype)
                    cuda.memcpy_dtoh(host_arr, cuda_buffers[name])
                    outputs[name] = host_arr
                    
                    # ç«‹å³æ£€æŸ¥è¾“å‡ºæ˜¯å¦å…¨é›¶
                    if np.all(host_arr == 0):
                        print(f"âš ï¸ è­¦å‘Š: è¾“å‡º {name} å…¨éƒ¨ä¸º0!")
                    else:
                        print(f"âœ… æˆåŠŸæ‹·è´è¾“å‡º: {name}, éé›¶å€¼èŒƒå›´: [{host_arr.min():.6f}, {host_arr.max():.6f}]")
                        
                except Exception as e:
                    print(f"âŒ æ‹·è´è¾“å‡º {name} å¤±è´¥: {e}")
            else:
                print(f"âŒ è¾“å‡ºtensor '{name}' ä¸åœ¨cuda_buffersä¸­")

# -----------------------------
# è¾“å‡ºæ£€æŸ¥
# -----------------------------
print("\n=== æ¨ç†è¾“å‡ºæ£€æŸ¥ ===")
all_zeros = True
for name, arr in outputs.items():
    if arr.size == 0:
        print(f"Layer {name}: dtype={arr.dtype}, empty array!")
        continue
    
    max_val = arr.max() if arr.size > 0 else 0
    min_val = arr.min() if arr.size > 0 else 0
    mean_val = arr.mean() if arr.size > 0 else 0
    
    print(f"Layer {name}: dtype={arr.dtype}, shape={arr.shape}")
    print(f"  max={max_val:.6f}, min={min_val:.6f}, mean={mean_val:.6f}")
    
    if not np.all(arr == 0):
        all_zeros = False
        
    if arr.dtype == np.float16:
        if max_val > 65504 or min_val < -65504:
            print(f"âš ï¸ Layer {name} è¶…å‡º FP16 èŒƒå›´ï¼")
    elif arr.dtype == np.float32:
        if np.isnan(arr).any() or np.isinf(arr).any():
            print(f"âš ï¸ Layer {name} åŒ…å« NaN æˆ– Infï¼")

if all_zeros:
    print("\nâŒ æ‰€æœ‰è¾“å‡ºéƒ½æ˜¯0ï¼å¯èƒ½çš„é—®é¢˜ï¼š")
    print("1. è¾“å…¥æ•°æ®æ²¡æœ‰æ­£ç¡®ä¼ é€’")
    print("2. æ¨¡å‹æ„å»ºæœ‰é—®é¢˜")
    print("3. åŠ¨æ€shapeè®¾ç½®ä¸æ­£ç¡®")
    print("4. FP16ç²¾åº¦æŸå¤±å¤ªå¤§ï¼Œå°è¯•ä½¿ç”¨FP32")

# -----------------------------
# ä¿å­˜ JSON + base64
# -----------------------------
if outputs:
    json_dict = {"lst": [[None, [{"outputs": {}}]]]}
    for name, arr in outputs.items():
        bio = io.BytesIO()
        np.save(bio, arr, allow_pickle=True)
        b64str = base64.b64encode(bio.getvalue()).decode("ascii")
        json_dict["lst"][0][1][0]["outputs"][name] = {
            "dtype": str(arr.dtype),
            "values": {"array": b64str}
        }

    with open(output_json_path, "w") as f:
        json.dump(json_dict, f)

    print(f"\nâœ… å·²ä¿å­˜è¾“å‡ºåˆ° {output_json_path}")
    print(f"âœ… æ€»å…±ä¿å­˜äº† {len(outputs)} ä¸ªè¾“å‡ºå¼ é‡")
else:
    print("\nâŒ æ²¡æœ‰è¾“å‡ºæ•°æ®å¯ä»¥ä¿å­˜")
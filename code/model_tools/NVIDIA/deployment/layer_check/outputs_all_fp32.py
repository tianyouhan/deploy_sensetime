import tensorrt as trt
import numpy as np
import os
import json
import io
import base64
from polygraphy.backend.trt import TrtRunner

# -----------------------------
# é…ç½®
# -----------------------------
onnx_path = "/mnt/data/hantianyou/occ_pred/spetr_occ_1212.onnx"
engine_path = "/mnt/data/hantianyou/occ_pred/spetr_occ_1212_fp32.trt"
output_json_path = "/mnt/data/hantianyou/road_compare_tool/layer_check/save_outputs/outputs_fp32_all.json"
input_dir = "/mnt/data/hantianyou/occ_pred/spetr_occ_input_1212_10000"

TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
trt.init_libnvinfer_plugins(TRT_LOGGER, "")

# =============================
# ==== ONNX -> TRT engine æ„å»º ====
# =============================
builder = trt.Builder(TRT_LOGGER)
network_flags = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)
network = builder.create_network(network_flags)

# è§£æ ONNX
parser = trt.OnnxParser(network, TRT_LOGGER)
with open(onnx_path, "rb") as f:
    if not parser.parse(f.read()):
        for i in range(parser.num_errors):
            print(parser.get_error(i))
        raise RuntimeError("ONNX parse failed")

# -----------------------------
# æ ‡è®°æ‰€æœ‰ä¸­é—´å±‚è¾“å‡º
# -----------------------------
for i in range(network.num_layers):
    layer = network.get_layer(i)
    for j in range(layer.num_outputs):
        tensor = layer.get_output(j)
        if tensor is not None and not tensor.is_network_output:
            network.mark_output(tensor)

# -----------------------------
# é…ç½®åŠ¨æ€shape
# -----------------------------
config = builder.create_builder_config()
# config.set_flag(trt.BuilderFlag.STRONGLY_TYPED)

# åˆ›å»ºä¼˜åŒ–profileå¤„ç†åŠ¨æ€shape
profile = builder.create_optimization_profile()

# è·å–è¾“å…¥åç§°å’Œshape
# inputs = {}
# input_shapes = {}
# for fname in os.listdir(input_dir):
#     if fname.endswith(".npy"):
#         key = fname.replace(".npy", "")
#         arr = np.load(os.path.join(input_dir, fname)).astype(np.float32)
#         inputs[key] = arr
#         input_shapes[key] = arr.shape
inputs = {}
input_shapes = {}

for name in os.listdir(input_dir):
    subdir = os.path.join(input_dir, name)
    if not os.path.isdir(subdir):
        continue

    npy_path = os.path.join(subdir, "0.npy")
    bin_path = os.path.join(subdir, "0.bin")
    shape_path = os.path.join(subdir, "shape.json")

    if os.path.exists(npy_path):
        # ---------- npy ----------
        arr = np.load(npy_path)
        if arr.dtype != np.float32:
            arr = arr.astype(np.float32)

        inputs[name] = arr
        input_shapes[name] = arr.shape
        print(f"âœ… åŠ è½½ npy è¾“å…¥: {name}, shape={arr.shape}")

    elif os.path.exists(bin_path):
        # ---------- bin ----------
        if not os.path.exists(shape_path):
            print(f"âŒ {subdir} ä¸­å­˜åœ¨ 0.bin ä½†ç¼ºå°‘ shape.jsonï¼Œè·³è¿‡")
            continue

        with open(shape_path, "r") as f:
            meta = json.load(f)

        dtype = np.dtype(meta["dtype"])
        shape = tuple(meta["shape"])

        arr = np.fromfile(bin_path, dtype=dtype).reshape(shape)

        if arr.dtype != np.float32:
            arr = arr.astype(np.float32)

        inputs[name] = arr
        input_shapes[name] = arr.shape
        print(f"âœ… åŠ è½½ bin è¾“å…¥: {name}, shape={arr.shape}")

    else:
        print(f"âš ï¸ è·³è¿‡ {subdir}ï¼Œæ—¢æ²¡æœ‰ 0.npy ä¹Ÿæ²¡æœ‰ 0.bin")

print("âœ… å·²åŠ è½½è¾“å…¥ï¼š", list(inputs.keys()))

# ä¸ºæ¯ä¸ªè¾“å…¥è®¾ç½®åŠ¨æ€èŒƒå›´
for i in range(network.num_inputs):
    input_tensor = network.get_input(i)
    input_name = input_tensor.name
    
    if input_name in input_shapes:
        shape = input_shapes[input_name]
        # è®¾ç½®æœ€å°ã€æœ€ä¼˜ã€æœ€å¤§shape
        # è¿™é‡Œä½¿ç”¨ç›¸åŒçš„shapeï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
        min_shape = shape
        opt_shape = shape  
        max_shape = shape
        
        print(f"è®¾ç½®è¾“å…¥ '{input_name}' çš„shapeèŒƒå›´: min{min_shape}, opt{opt_shape}, max{max_shape}")
        profile.set_shape(input_name, min_shape, opt_shape, max_shape)
    else:
        print(f"è­¦å‘Š: è¾“å…¥ '{input_name}' æœªåœ¨è¾“å…¥æ•°æ®ä¸­æ‰¾åˆ°")

config.add_optimization_profile(profile)
# print("ğŸ” æ£€æŸ¥ç½‘ç»œå±‚ç²¾åº¦è®¾ç½®:")
# for i in range(network.num_layers):
#     layer = network.get_layer(i)
#     layer_type_str = str(layer.type)
#     print(f"[{i:4d}] {layer.name:60s} | type={layer_type_str:25s} | precision={layer.precision} | "
#         f"input_types={[layer.get_input(i).dtype for i in range(layer.num_inputs)]} "
#         f"-> output_types={[layer.get_output(i).dtype for i in range(layer.num_outputs)]}")
# -----------------------------
# æ„å»º engine
# -----------------------------
serialized_engine = builder.build_serialized_network(network, config)
if serialized_engine is None:
    raise RuntimeError("Failed to build engine!")

with open(engine_path, "wb") as f:
    f.write(serialized_engine)

print(f"âœ… å·²ç”Ÿæˆæ”¯æŒåŠ¨æ€shapeçš„FP32 engine: {engine_path}")

# =============================
# ==== æ¨ç† ====
# =============================
runtime = trt.Runtime(TRT_LOGGER)
with open(engine_path, "rb") as f:
    engine = runtime.deserialize_cuda_engine(f.read())

# ä½¿ç”¨ Polygraphy TrtRunner æ¨ç†
runner = TrtRunner(engine)
runner.activate()

# è®¾ç½®æ‰§è¡Œcontextçš„shape
context = runner.context
for input_name, arr in inputs.items():
    # TensorRT 10+ ä½¿ç”¨ set_input_shape
    if hasattr(context, "set_input_shape"):
        context.set_input_shape(input_name, arr.shape)
    else:
        context.set_binding_shape(engine.get_binding_index(input_name), arr.shape)

outputs = runner.infer(feed_dict=inputs)
runner.deactivate()

# -----------------------------
# ä¿å­˜è¾“å‡º
# -----------------------------
json_dict = {"lst": [[None, [{"outputs": {}}]]]}
for name, arr in outputs.items():
    bio = io.BytesIO()
    np.save(bio, arr, allow_pickle=False)
    b64str = base64.b64encode(bio.getvalue()).decode("ascii")
    json_dict["lst"][0][1][0]["outputs"][name] = {"values": {"array": b64str}}

with open(output_json_path, "w") as f:
    json.dump(json_dict, f)

print(f"âœ… å·²ä¿å­˜æ‰€æœ‰ä¸­é—´å±‚è¾“å‡ºåˆ° {output_json_path}")